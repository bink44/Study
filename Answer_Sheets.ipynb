{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bink44/Study/blob/main/Answer_Sheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EE 599 Reading Assignment \\# 1:\n",
        "You can access paper using this [link](https://courses.cs.washington.edu/courses/cse550/21au/papers/CSE550.Eyeriss.pdf), do not re-distribute the paper."
      ],
      "metadata": {
        "id": "JA0rETRQZBON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1: (1 Point)\n",
        "\n",
        "**Disallowed** list:\n",
        "- You **MAY NOT** collaborate with anyone else on this assignment. This means you cannot talk to anyone else about the assignment until after deadline.\n",
        "- You **MAY NOT** use ChatGPT and services like that\n",
        "\n",
        "**Allowed** list:\n",
        "- Notes including any slides from the class\n",
        "- The textbooks\n",
        "- The given paper"
      ],
      "metadata": {
        "id": "s-HWWv6kaxrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A1:\n",
        "\n",
        "I affirm I have read these exam rules and will follow them. Failure to do so may subject me to sanctions including an F in the course.\n",
        "\n",
        "**Type your full name to affirm you have read the above statement:**\n",
        "\n",
        "Yubin Kwon"
      ],
      "metadata": {
        "id": "Pz0uD-nHbHuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## Q2.1 Summary (24 Points):\n",
        "\n",
        "Summarize the main objectives and contributions of the paper."
      ],
      "metadata": {
        "id": "XzNWLVCLbcjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A2.1:\n",
        "This paper introduces Eyeriss: an energy-efficient reconfigurable accelerator for deep CNNs. Due to the features of CNNs, it is widely used in AI fields but have challenges on energy efficiency- it is energy consuming largely on data movement. Eyeriss is approaching this challenge with its dataflow and architecture. With row stationary on 168 PEs, it reuses data types of filter weight/ifmap pixel. Also, data compression and data gating exploit reduces energy cost, too. The performance is explemented on 2 common CNNs, AlexNet and VGG-16. This research gives better performance of CNNs on low-energy."
      ],
      "metadata": {
        "id": "0j5A4_Zfbpra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.2 Comprehension (15 Points):\n",
        "- What problem is the paper addressing?\n",
        "- How does the Eyeriss architecture differ from other architectures you are familiar with?"
      ],
      "metadata": {
        "id": "IE2n5UQHbuZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A2.2:\n",
        "**Problem**:  Even though Deep learning with CNNs has achieved high accuracy, it requires enumerous mbs of parameters on billions of operations with a single inference pass. This consumes lots of energy, so optimization is required for energy efficiency.\n",
        "\n",
        "**Speciality of Eyeriss architecture**: Eyeriss is CNN accelerator, with the following 4 features.\n",
        "\n",
        "1) A spatial architecture with an array of 168 PEs (processing elements)\n",
        "\n",
        "2) RS (Row Stationary); CNN dataflow\n",
        "\n",
        "3) NoC (Network-on-Chip) architecture; uses both multicast & point-to-point single cycle data delivery; support the RS flow\n",
        "\n",
        "4) RLC (Run-length Compression) and PE data gating\n",
        "\n",
        "these features are speciality of Eyeriss, which imporves energy efficiency.\n",
        "\n",
        "Based on as far as I know about other architecture, the most significant part of Eyeriss architecture is that this is Network on Chip which can run CNN dataflow with efficient energy consuming."
      ],
      "metadata": {
        "id": "9O7k2DbXcNp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.3 Technical Deep Dive (15 Points):\n",
        "- Describe the spatial architecture of Eyeriss in your own words.\n",
        "- How does the Eyeriss architecture optimize energy efficiency in dataflow for CNNs?\n",
        "- What are the main challenges in designing an energy-efficient architecture for CNNs, and how does Eyeriss tackle these challenges?"
      ],
      "metadata": {
        "id": "PnzcxvhWckY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.3:\n",
        "- Spatial architecture of Eyeriss:\n",
        "It can be divided into 2 parts, **the core clock domain** for processing, and **the linke clock domain** for communication with the off-chip.\n",
        "\n",
        "  The core clock main is made of 168 PEs as a 12x14 rectangle, a 108kb GLB(graph learning benchmarks), an RLC CODEC, and an ReLU module.\n",
        "\n",
        "  4 levels of memory hierarchy is; DRAM, GLB, inter-PE communication, and spads\n",
        "\n",
        "- Energy Optimization in dataflow for CNNs\n",
        "1) reducing data movement 2) exploiting data statics\n",
        "\n",
        "  For 1), Row Stationary dataflow\n",
        "  \n",
        "  RS dataflow optimizes data movement for all types of data, therefore reduce energy consume. The reused data types and how are as follows:\n",
        "  \n",
        "  * Convolutional - reuse filter weight ExF times in ifmap plane, ifmap pixel RxS times in filter plane\n",
        "\n",
        "  * Filter - reuse filter weight across the batch of N ifmaps\n",
        "\n",
        "  * Ifmap - reuse ifmap pixel across M filters\n",
        "\n",
        "  For 2),\n",
        "  1. reduce DRAM accesses when using compression\n",
        "  ( compression is the data movement that uses most energy)\n",
        "  2. skip the unnecessary computations\n",
        "\n",
        "  RLC (Run Length Compression) and PE data gating exploit the statistics of zero data\n",
        "\n",
        "- The main challenges of creating an energy-efficient architecture for CNNs and reason\n",
        "\n",
        "  Main challenge is: to minimize data movement energy cost.\n",
        "  \n",
        "  The reason is: CNNs' computation needs a large amount of data, while creating notable data movement between on-chip and off-chip, which is energy consuming compared to computation\n",
        "\n",
        "- How Eyeriss tries to overcome these challenges\n",
        "\n",
        "  Eyeriss propose solution to this challenge by using RS (row stationary) dataflow, on a spatial architecture with 168 PEs."
      ],
      "metadata": {
        "id": "sv3rFNjpcuID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.4 Evaluation (15 Points):\n",
        "- What were the key results or findings of the paper? Were they compelling?\n",
        "- How do the authors validate their claims or results? Are there any weaknesses in their methodology?"
      ],
      "metadata": {
        "id": "HRBvFutTc2uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.4:\n",
        "Key Results:\n",
        "\n",
        "Eyeriss is evaluated its performance on 2 major CNNs, AlexNet and VGG-16.\n",
        "\n",
        "**1.on AlexNet:**\n",
        "\n",
        "frame rate: 34.7 frames/s\n",
        "\n",
        "processing throughput: 23.1 GMACS\n",
        "\n",
        "chip power: 278 mW\n",
        "\n",
        "energy efficiency: 83.1 GMACS/W\n",
        "\n",
        "(reason for actual throughput being lower than the peak one)\n",
        "- only 88% of the PEs active\n",
        "- time consuming while loading dat from the GLB into the PE array\n",
        "- no processing of the chip while it is loading ifmap / dumping ofmaps from DRAM\n",
        "\n",
        "**2.on VGG-16:**\n",
        "\n",
        "average frame rates: 0.7 frames/s\n",
        "\n",
        "power consumption: 236 mW\n",
        "\n",
        "\n",
        "VGG-16 requires 23 times mor computations/frame than AlexNet\n",
        "\n",
        "\n",
        "**How they validate? Any weakness on methodologies?**\n",
        "\n",
        "The authors of the paper is validating the performance with the evaluation of the chip with 2 major CNNs. This is very meaningful since they did actual experiment with chip out. However, In my opinion, I think the result part of the paper is not very specific. Since the evaluating parameters of the 2 CNNs are not identical, and I am not aware of the usual value (not using Eyeriss) of them, I could not see how to interpret the results. Still, this can be the reason of my lack of knowledge, so I cannot say it is weakness of the methodology.\n",
        "\n",
        "In conclusion, I think maybe more specific comparison could have been useful to show the improved performance of Eyeriss better.\n"
      ],
      "metadata": {
        "id": "xKUL8nhTdNLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.5 Contextual Understanding (10 Points):\n",
        "- How does this work fit into the larger context of neural network architectures and energy efficiency?\n",
        "- Can the principles of Eyeriss be applied to other deep learning architectures beyond CNNs?\n"
      ],
      "metadata": {
        "id": "Fp_FV2bzdV4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.5:\n",
        "\n",
        "- Eyeriss has significant methods of data reusing and data compression, which increases energy efficiency. It could be also used in improving other type of neural network architecture.\n",
        "\n",
        "- Since CNN is not easy to parallelize due to its characteristics of frequent memory accesses and impossibility of doing convolution&pooling together. Eyeriss reduced energy cost in this base features of CNN. Therefore, it might be not useful in some of the neural networks which does not share similar features of CNN. However, if any neural network in similar situation could be improved using methods of Eyeriss."
      ],
      "metadata": {
        "id": "OvpxYhvNdg18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.6 Discussion and Critique (10 points):\n",
        "- Are there any assumptions made by the authors that you disagree with or find questionable?\n",
        "- Do you think there are potential improvements or future directions not addressed by the authors?\n",
        "- How would you compare Eyeriss with other architectures or solutions you know of?\n",
        "\n"
      ],
      "metadata": {
        "id": "cxUpnGmtdjfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.6:\n",
        "\n",
        "- Could not find questionable parts. If I have to say, the result part was not very interpretable\n",
        "\n",
        "- When explaining the result on AlexNet, some limitations were mentioned as 1) only 88% PEs active, 2) time to load data from GLB into the PE array, 3) no chip performance when loading/dumping from DRAM. Therefore, finding the ways to make all the PEs active or reducing loading/dumping time of GLB and DRAM could be future directions.\n",
        "\n",
        "- As we learned about various dataflows from the lecture, I think the comparison of row stationary to other dataflows is one possibility."
      ],
      "metadata": {
        "id": "cjAQy1qLdvZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Q2.7 Reflection (10 Points):\n",
        "- What was the most surprising or counterintuitive thing you learned from this paper?\n",
        "- How has reading this paper influenced your views on the importance of energy efficiency in deep learning?\n",
        "\n"
      ],
      "metadata": {
        "id": "hSMCnPg8d_0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2.7:\n",
        "\n",
        "I thought it is alomost impossible to run CNNs on smaller computers without wifi on it, such as mobile phone in off-line state or other devices. It is my belief that for better neural network, better performance device is necessary, therefore need to be connected online at least. However, after reading this paper, my belief has totally changed. The architecture's energy efficiency is another way to improve deep learning - by enabling the possibility of deep learning into more various fields."
      ],
      "metadata": {
        "id": "nBtgEgPXeNR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Turn in your reading assignment by saving this answer sheet back to the Github repository."
      ],
      "metadata": {
        "id": "mnRyd9Iie6Dz"
      }
    }
  ]
}